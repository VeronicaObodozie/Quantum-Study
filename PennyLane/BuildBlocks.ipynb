{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883dc58f",
   "metadata": {},
   "source": [
    "# PennyLane Building Blocks of a Quantum Neural Network.\n",
    "This notebook explains the templates, layers and overview pf how to make a Quantum Model.\n",
    "\n",
    "## Input -> Encode classical data\n",
    "The quantum model input needs to be encoded using an embedding circuit. PennyLane has a few of these\n",
    "* Basis: this is used for integer or binary\n",
    "* Amplitude Encoding: Normalized to 2^n, pad if data is not in right form. Data Types Integer, float, complex. A sum of features must equal 1\n",
    "* Displacement\n",
    "* Angle Embedding: N features in n qubits with rotation angles. N<= n>\n",
    "\n",
    "## Using Entangled circuits to create layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48787230",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import useful packages\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a69a5d",
   "metadata": {},
   "source": [
    "## Input styles\n",
    "\n",
    "Basis Embedding\n",
    "\n",
    "Amplitude Encoding: Integers/foat/complex\n",
    "\n",
    "Angle Embedding: Integer/Float/Complex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91023b4e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# BasisEmbedding\n",
    "wires = 2\n",
    "basis_dev = qml.device('default.qubit, wires)\n",
    "@qml.qnode(basis_dev)\n",
    "def basis_encoder(data):\n",
    "    qml.BasisEmbedding(data, wires)\n",
    "    return qml.state()\n",
    "\n",
    "# Angle Embedding\n",
    "angle_dev = qml.device('default.qubit, wires)\n",
    "@qml.qnode(angle_dev)\n",
    "def angle_encoder(data):\n",
    "    qml.AngleEmbedding(features=data, wires=wires, rotation = 'X')\n",
    "    return qml.state()\n",
    "\n",
    "# Displacement Embedding\n",
    "# Amplitude Encoding\n",
    "amp_dev = qml.device('default.qubit, wires)\n",
    "@qml.qnode(amp_dev)\n",
    "def amp_encoder(data):\n",
    "    qml.AmplitudeEmbedding(data, wires, pad_width= 0, normalize= True)\n",
    "    return qml.state()\n",
    "\n",
    "# QOADO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f99fce",
   "metadata": {},
   "source": [
    "## Entangled templates\n",
    "PennyLane has multiple templates for \n",
    "\n",
    "### Basic Entangled layers\n",
    "\n",
    "### Random Layers\n",
    "\n",
    "### CVNeural Net layers\n",
    "\n",
    "### Strongly entangled layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776b1c08",
   "metadata": {},
   "source": [
    "## Typical Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b61ad",
   "metadata": {},
   "source": [
    "### Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f86ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2 Qubit FCN layer for quantum applications\n",
    "n_qubits = 2\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "# Create weight shape\n",
    "n_layers = 6\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
    "# layer shape is (layers x qubits) so this example is 6 x 2\n",
    "\n",
    "# Converting to layer\n",
    "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "\n",
    "# Sequential model\n",
    "clayer_1 = torch.nn.Linear(2, 2)\n",
    "clayer_2 = torch.nn.Linear(2, 2)\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "layers = [clayer_1, qlayer, clayer_2, softmax]\n",
    "model = torch.nn.Sequential(*layers)\n",
    "\n",
    "# General model\n",
    "class HybridModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.clayer_1 = torch.nn.Linear(2, 4)\n",
    "        self.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer_2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.clayer_2 = torch.nn.Linear(4, 2)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.clayer_1(x)\n",
    "        x_1, x_2 = torch.split(x, 2, dim=1)\n",
    "        x_1 = self.qlayer_1(x_1)\n",
    "        x_2 = self.qlayer_2(x_2)\n",
    "        x = torch.cat([x_1, x_2], axis=1)\n",
    "        x = self.clayer_2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "model = HybridModel()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
